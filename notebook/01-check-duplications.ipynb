{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b18c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: C:\\Users\\nevis\\Documents\\Msc_2\\mélytanulás\\vitmma19-pw-main\\vitmma19-pw\\data\\processed\\legal_text_decoder\\train.csv\n",
      "Val path:   C:\\Users\\nevis\\Documents\\Msc_2\\mélytanulás\\vitmma19-pw-main\\vitmma19-pw\\data\\processed\\legal_text_decoder\\val.csv\n",
      "Test path:  C:\\Users\\nevis\\Documents\\Msc_2\\mélytanulás\\vitmma19-pw-main\\vitmma19-pw\\data\\processed\\legal_text_decoder\\test.csv\n",
      "\n",
      "=== TRAIN SPLIT ===\n",
      "Összes minta: 2524\n",
      "- Egyedi normalizált szövegek száma: 2524\n",
      "- Duplikált szöveg-előfordulások száma ugyanabban a splitben: 0\n",
      "- Egyedi (text_norm, label) párok száma: 2524\n",
      "- Duplikált (text_norm, label) párok száma ugyanabban a splitben: 0\n",
      "\n",
      "=== VAL SPLIT ===\n",
      "Összes minta: 541\n",
      "- Egyedi normalizált szövegek száma: 541\n",
      "- Duplikált szöveg-előfordulások száma ugyanabban a splitben: 0\n",
      "- Egyedi (text_norm, label) párok száma: 541\n",
      "- Duplikált (text_norm, label) párok száma ugyanabban a splitben: 0\n",
      "\n",
      "=== TEST SPLIT ===\n",
      "Összes minta: 541\n",
      "- Egyedi normalizált szövegek száma: 541\n",
      "- Duplikált szöveg-előfordulások száma ugyanabban a splitben: 0\n",
      "- Egyedi (text_norm, label) párok száma: 541\n",
      "- Duplikált (text_norm, label) párok száma ugyanabban a splitben: 0\n",
      "\n",
      "=== ÁTFEDÉSEK SPLITEK KÖZÖTT (csak text_norm alapján) ===\n",
      "train ∩ val  (text_norm): 0\n",
      "train ∩ test (text_norm): 0\n",
      "val   ∩ test (text_norm): 0\n",
      "\n",
      "=== ÁTFEDÉSEK SPLITEK KÖZÖTT ((text_norm, label) párok) ===\n",
      "train ∩ val  párok: 0\n",
      "train ∩ test párok: 0\n",
      "val   ∩ test párok: 0\n",
      "\n",
      "==== Duplikáció-ellenőrzés kész. ====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gyors duplikáció-ellenőrző script train / val / test között.\n",
    "\n",
    "Ellenőrzések:\n",
    "1) Vannak-e duplán szereplő szövegek EGY spliten belül?\n",
    "2) Ugyanaz a szöveg előfordul-e több splitben is?\n",
    "3) Ugyanaz a (text, label) pár előfordul-e több splitben is?\n",
    "\n",
    "Kimenet: sima print-ek a konzolra.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import config\n",
    "PROCESSED_DIR = Path(config.PROCESSED_DATA_DIR)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Egyszerű normalizálás:\n",
    "    - strip whitespace\n",
    "    - több whitespace -> egy szóköz\n",
    "    - (opcionális) lower() – ha case-insensitive akarsz lenni\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    s = \" \".join(s.split())\n",
    "    # ha szeretnéd, legyen case-insensitive:\n",
    "    # s = s.lower()\n",
    "    return s\n",
    "\n",
    "\n",
    "def load_splits():\n",
    "    train_path = Path(PROCESSED_DIR / \"train.csv\")\n",
    "    val_path = Path(PROCESSED_DIR / \"val.csv\")\n",
    "    test_path = Path(PROCESSED_DIR / \"test.csv\")\n",
    "\n",
    "    print(\"Train path:\", train_path)\n",
    "    print(\"Val path:  \", val_path)\n",
    "    print(\"Test path: \", test_path)\n",
    "\n",
    "    for p in (train_path, val_path, test_path):\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"Hiányzik a fájl: {p}\")\n",
    "\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_val = pd.read_csv(val_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "def check_within_split(name, df):\n",
    "    print(f\"\\n=== {name.upper()} SPLIT ===\")\n",
    "    print(f\"Összes minta: {len(df)}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"text_norm\"] = df[\"text\"].apply(normalize_text)\n",
    "\n",
    "    n_total = len(df)\n",
    "    n_unique_text = df[\"text_norm\"].nunique()\n",
    "    n_dup_text = n_total - n_unique_text\n",
    "\n",
    "    print(f\"- Egyedi normalizált szövegek száma: {n_unique_text}\")\n",
    "    print(f\"- Duplikált szöveg-előfordulások száma ugyanabban a splitben: {n_dup_text}\")\n",
    "\n",
    "    # (text_norm, label) párok\n",
    "    n_unique_pair = df[[\"text_norm\", \"label\"]].drop_duplicates().shape[0]\n",
    "    n_dup_pair = n_total - n_unique_pair\n",
    "\n",
    "    print(f\"- Egyedi (text_norm, label) párok száma: {n_unique_pair}\")\n",
    "    print(f\"- Duplikált (text_norm, label) párok száma ugyanabban a splitben: {n_dup_pair}\")\n",
    "\n",
    "    if n_dup_text > 0:\n",
    "        print(\"\\nTOP 5 duplikált szöveg a spliten belül:\")\n",
    "        dup_texts = (\n",
    "            df.groupby(\"text_norm\")\n",
    "            .size()\n",
    "            .reset_index(name=\"count\")\n",
    "            .sort_values(\"count\", ascending=False)\n",
    "        )\n",
    "        for _, row in dup_texts.head(5).iterrows():\n",
    "            print(f\"  count={row['count']} | text_norm='{row['text_norm'][:120]}...'\")\n",
    "\n",
    "\n",
    "def check_cross_splits(df_train, df_val, df_test):\n",
    "    # normalizált szöveg + label készítése\n",
    "    for df in (df_train, df_val, df_test):\n",
    "        df[\"text_norm\"] = df[\"text\"].apply(normalize_text)\n",
    "\n",
    "    train_texts = set(df_train[\"text_norm\"])\n",
    "    val_texts = set(df_val[\"text_norm\"])\n",
    "    test_texts = set(df_test[\"text_norm\"])\n",
    "\n",
    "    print(\"\\n=== ÁTFEDÉSEK SPLITEK KÖZÖTT (csak text_norm alapján) ===\")\n",
    "    inter_train_val = train_texts & val_texts\n",
    "    inter_train_test = train_texts & test_texts\n",
    "    inter_val_test = val_texts & test_texts\n",
    "\n",
    "    print(f\"train ∩ val  (text_norm): {len(inter_train_val)}\")\n",
    "    print(f\"train ∩ test (text_norm): {len(inter_train_test)}\")\n",
    "    print(f\"val   ∩ test (text_norm): {len(inter_val_test)}\")\n",
    "\n",
    "    def show_examples(name, s):\n",
    "        if not s:\n",
    "            return\n",
    "        print(f\"\\nPéldák {name} átfedésre (text_norm):\")\n",
    "        for i, txt in enumerate(list(s)[:5]):\n",
    "            print(f\"  [{i}] '{txt[:120]}...'\")\n",
    "\n",
    "    show_examples(\"train ∩ val\", inter_train_val)\n",
    "    show_examples(\"train ∩ test\", inter_train_test)\n",
    "    show_examples(\"val ∩ test\", inter_val_test)\n",
    "\n",
    "    # (text_norm, label) párok\n",
    "    def pairs(df):\n",
    "        return set(zip(df[\"text_norm\"], df[\"label\"]))\n",
    "\n",
    "    train_pairs = pairs(df_train)\n",
    "    val_pairs = pairs(df_val)\n",
    "    test_pairs = pairs(df_test)\n",
    "\n",
    "    inter_p_train_val = train_pairs & val_pairs\n",
    "    inter_p_train_test = train_pairs & test_pairs\n",
    "    inter_p_val_test = val_pairs & test_pairs\n",
    "\n",
    "    print(\"\\n=== ÁTFEDÉSEK SPLITEK KÖZÖTT ((text_norm, label) párok) ===\")\n",
    "    print(f\"train ∩ val  párok: {len(inter_p_train_val)}\")\n",
    "    print(f\"train ∩ test párok: {len(inter_p_train_test)}\")\n",
    "    print(f\"val   ∩ test párok: {len(inter_p_val_test)}\")\n",
    "\n",
    "    def show_pair_examples(name, s):\n",
    "        if not s:\n",
    "            return\n",
    "        print(f\"\\nPéldák {name} átfedő (text_norm, label) párokra:\")\n",
    "        for i, (txt, lab) in enumerate(list(s)[:5]):\n",
    "            print(f\"  [{i}] label={lab} | text_norm='{txt[:120]}...'\")\n",
    "\n",
    "    show_pair_examples(\"train ∩ val\", inter_p_train_val)\n",
    "    show_pair_examples(\"train ∩ test\", inter_p_train_test)\n",
    "    show_pair_examples(\"val ∩ test\", inter_p_val_test)\n",
    "\n",
    "\n",
    "def main():\n",
    "    df_train, df_val, df_test = load_splits()\n",
    "\n",
    "    check_within_split(\"train\", df_train)\n",
    "    check_within_split(\"val\", df_val)\n",
    "    check_within_split(\"test\", df_test)\n",
    "\n",
    "    check_cross_splits(df_train, df_val, df_test)\n",
    "\n",
    "    print(\"\\n==== Duplikáció-ellenőrzés kész. ====\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
